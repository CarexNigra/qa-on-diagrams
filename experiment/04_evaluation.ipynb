{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel, t\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import answer_correctness\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT-4o to Evaluate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/qna_results.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "len(results[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", api_key=api_key)\n",
    "evaluator_llm = LangchainLLMWrapper(chat_model)\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=api_key)\n",
    "run_config = RunConfig(max_workers=2) # reduce to 2, to not reach token/min throughput limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_keys = [k for k in list(results.keys()) if k.endswith((\"text\", \"image\"))]\n",
    "for answer_key in answers_keys:\n",
    "    data_samples = {\n",
    "        'question': results[\"question\"],\n",
    "        'answer': results[answer_key],\n",
    "        'ground_truth': results[\"answer\"],\n",
    "    }\n",
    "    \n",
    "    dataset = Dataset.from_dict(data_samples)\n",
    "    eval_results = evaluate(\n",
    "        dataset, \n",
    "        llm=evaluator_llm, \n",
    "        embeddings=embedder, \n",
    "        metrics=[answer_correctness],\n",
    "        run_config=run_config,\n",
    "    )\n",
    "    \n",
    "    with open(f\"./data/eval_{answer_key}.json\", \"w\") as f:\n",
    "        json.dump(eval_results.scores, f)\n",
    "        \n",
    "    time.sleep(10) # wait for 10sec just for rate limiting \n",
    "    print(f\"{answer_key} | {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Evaluation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>gpt_text_metrics</th>\n",
       "      <th>gpt_text_img_metrics</th>\n",
       "      <th>claude_text_metrics</th>\n",
       "      <th>claude_text_img_metrics</th>\n",
       "      <th>qwen_text_metrics</th>\n",
       "      <th>qwen_text_img_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2102.09837v1-Figure2-1.png</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.524383</td>\n",
       "      <td>0.570533</td>\n",
       "      <td>0.442720</td>\n",
       "      <td>0.497537</td>\n",
       "      <td>0.713690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2102.09837v1-Figure2-1.png</td>\n",
       "      <td>question_2</td>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.726113</td>\n",
       "      <td>0.498398</td>\n",
       "      <td>0.444328</td>\n",
       "      <td>0.708439</td>\n",
       "      <td>0.595063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2210.01528v1-Figure3-1.png</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.133522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134909</td>\n",
       "      <td>0.189027</td>\n",
       "      <td>0.152380</td>\n",
       "      <td>0.212937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2210.01528v1-Figure3-1.png</td>\n",
       "      <td>question_2</td>\n",
       "      <td>0.108546</td>\n",
       "      <td>0.551472</td>\n",
       "      <td>0.133453</td>\n",
       "      <td>0.503272</td>\n",
       "      <td>0.135934</td>\n",
       "      <td>0.212770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2205.13948v1-Figure4-1.png</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.170197</td>\n",
       "      <td>0.969128</td>\n",
       "      <td>0.587855</td>\n",
       "      <td>0.149822</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>0.165061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image_id   questions  gpt_text_metrics  \\\n",
       "0  2102.09837v1-Figure2-1.png  question_1          0.706173   \n",
       "0  2102.09837v1-Figure2-1.png  question_2          0.713231   \n",
       "1  2210.01528v1-Figure3-1.png  question_1          0.133522   \n",
       "1  2210.01528v1-Figure3-1.png  question_2          0.108546   \n",
       "2  2205.13948v1-Figure4-1.png  question_1          0.170197   \n",
       "\n",
       "   gpt_text_img_metrics  claude_text_metrics  claude_text_img_metrics  \\\n",
       "0              0.524383             0.570533                 0.442720   \n",
       "0              0.726113             0.498398                 0.444328   \n",
       "1              1.000000             0.134909                 0.189027   \n",
       "1              0.551472             0.133453                 0.503272   \n",
       "2              0.969128             0.587855                 0.149822   \n",
       "\n",
       "   qwen_text_metrics  qwen_text_img_metrics  \n",
       "0           0.497537               0.713690  \n",
       "0           0.708439               0.595063  \n",
       "1           0.152380               0.212937  \n",
       "1           0.135934               0.212770  \n",
       "2           0.163915               0.165061  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Detailed results\n",
    "\n",
    "with open(\"./data/qna_results.json\", \"r\") as f:\n",
    "    results = json.load(f) \n",
    "\n",
    "df = pd.DataFrame(results['img_fname'], columns = ['image_id'])\n",
    "df['questions'] = json.dumps([\"question_1\" ,\"question_2\"])\n",
    "df['questions'] = df['questions'].apply(json.loads)\n",
    "df = df.explode('questions')\n",
    "\n",
    "with open(\"./data/eval_gpt_text.json\", \"r\") as f:\n",
    "    gpt_txt = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in gpt_txt]\n",
    "df[\"gpt_text_metrics\"] = evals\n",
    "\n",
    "with open(\"./data/eval_gpt_image.json\", \"r\") as f:\n",
    "    gpt_img = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in gpt_img]\n",
    "df[\"gpt_text_img_metrics\"] = evals\n",
    "\n",
    "\n",
    "with open(\"./data/eval_claude_text.json\", \"r\") as f:\n",
    "    claude_txt = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in claude_txt]\n",
    "df[\"claude_text_metrics\"] = evals\n",
    "\n",
    "with open(\"./data/eval_claude_image.json\", \"r\") as f:\n",
    "    claude_img = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in claude_img]\n",
    "df[\"claude_text_img_metrics\"] = evals\n",
    "\n",
    "\n",
    "with open(\"./data/eval_qwen_text.json\", \"r\") as f:\n",
    "    qwen_txt = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in qwen_txt]\n",
    "df[\"qwen_text_metrics\"] = evals\n",
    "\n",
    "with open(\"./data/eval_qwen_image.json\", \"r\") as f:\n",
    "    qwen_img = json.load(f) \n",
    "evals = [m['answer_correctness'] for m in qwen_img]\n",
    "df[\"qwen_text_img_metrics\"] = evals\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>gpt_text_metrics</th>\n",
       "      <th>gpt_text_img_metrics</th>\n",
       "      <th>claude_text_metrics</th>\n",
       "      <th>claude_text_img_metrics</th>\n",
       "      <th>qwen_text_metrics</th>\n",
       "      <th>qwen_text_img_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113902-Figure1-1.png</td>\n",
       "      <td>0.577814</td>\n",
       "      <td>0.631824</td>\n",
       "      <td>0.513554</td>\n",
       "      <td>0.560635</td>\n",
       "      <td>0.642430</td>\n",
       "      <td>0.729054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12030503-Figure3-1.png</td>\n",
       "      <td>0.407385</td>\n",
       "      <td>0.595792</td>\n",
       "      <td>0.614903</td>\n",
       "      <td>0.474205</td>\n",
       "      <td>0.295873</td>\n",
       "      <td>0.570915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245438-Figure1-1.png</td>\n",
       "      <td>0.351573</td>\n",
       "      <td>0.736119</td>\n",
       "      <td>0.426176</td>\n",
       "      <td>0.567392</td>\n",
       "      <td>0.388087</td>\n",
       "      <td>0.741965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339538-Figure3-1.png</td>\n",
       "      <td>0.592639</td>\n",
       "      <td>0.597931</td>\n",
       "      <td>0.435265</td>\n",
       "      <td>0.548215</td>\n",
       "      <td>0.591861</td>\n",
       "      <td>0.591870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1356505-Figure1-1.png</td>\n",
       "      <td>0.179031</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.390080</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.182323</td>\n",
       "      <td>0.409498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id  gpt_text_metrics  gpt_text_img_metrics  \\\n",
       "0    113902-Figure1-1.png          0.577814              0.631824   \n",
       "1  12030503-Figure3-1.png          0.407385              0.595792   \n",
       "2   1245438-Figure1-1.png          0.351573              0.736119   \n",
       "3   1339538-Figure3-1.png          0.592639              0.597931   \n",
       "4   1356505-Figure1-1.png          0.179031              0.374192   \n",
       "\n",
       "   claude_text_metrics  claude_text_img_metrics  qwen_text_metrics  \\\n",
       "0             0.513554                 0.560635           0.642430   \n",
       "1             0.614903                 0.474205           0.295873   \n",
       "2             0.426176                 0.567392           0.388087   \n",
       "3             0.435265                 0.548215           0.591861   \n",
       "4             0.390080                 0.529412           0.182323   \n",
       "\n",
       "   qwen_text_img_metrics  \n",
       "0               0.729054  \n",
       "1               0.570915  \n",
       "2               0.741965  \n",
       "3               0.591870  \n",
       "4               0.409498  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Means for each img\n",
    "\n",
    "df_per_question = df.groupby(\"image_id\").mean(numeric_only=True).reset_index()\n",
    "df_per_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt_text_metrics</th>\n",
       "      <th>gpt_text_img_metrics</th>\n",
       "      <th>claude_text_metrics</th>\n",
       "      <th>claude_text_img_metrics</th>\n",
       "      <th>qwen_text_metrics</th>\n",
       "      <th>qwen_text_img_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.686431</td>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.516647</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.644342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.237257</td>\n",
       "      <td>0.194232</td>\n",
       "      <td>0.196352</td>\n",
       "      <td>0.123554</td>\n",
       "      <td>0.220617</td>\n",
       "      <td>0.204615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.045757</td>\n",
       "      <td>0.148320</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.268063</td>\n",
       "      <td>0.086149</td>\n",
       "      <td>0.191939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.248163</td>\n",
       "      <td>0.555294</td>\n",
       "      <td>0.167165</td>\n",
       "      <td>0.426753</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>0.492318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.418022</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>0.385835</td>\n",
       "      <td>0.512457</td>\n",
       "      <td>0.391658</td>\n",
       "      <td>0.611778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.578456</td>\n",
       "      <td>0.853445</td>\n",
       "      <td>0.529812</td>\n",
       "      <td>0.574441</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>0.834822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.972150</td>\n",
       "      <td>0.999038</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>0.886968</td>\n",
       "      <td>0.973796</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gpt_text_metrics  gpt_text_img_metrics  claude_text_metrics  \\\n",
       "count        100.000000            100.000000           100.000000   \n",
       "mean           0.435584              0.686431             0.375950   \n",
       "std            0.237257              0.194232             0.196352   \n",
       "min            0.045757              0.148320             0.050011   \n",
       "25%            0.248163              0.555294             0.167165   \n",
       "50%            0.418022              0.676003             0.385835   \n",
       "75%            0.578456              0.853445             0.529812   \n",
       "max            0.972150              0.999038             0.827742   \n",
       "\n",
       "       claude_text_img_metrics  qwen_text_metrics  qwen_text_img_metrics  \n",
       "count               100.000000         100.000000             100.000000  \n",
       "mean                  0.516647           0.407300               0.644342  \n",
       "std                   0.123554           0.220617               0.204615  \n",
       "min                   0.268063           0.086149               0.191939  \n",
       "25%                   0.426753           0.182073               0.492318  \n",
       "50%                   0.512457           0.391658               0.611778  \n",
       "75%                   0.574441           0.547722               0.834822  \n",
       "max                   0.886968           0.973796               1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_question.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_image</th>\n",
       "      <th>absolute_uplift</th>\n",
       "      <th>relative_uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt</th>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.686431</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude</th>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.516647</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen</th>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.644342</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text_image  absolute_uplift  relative_uplift\n",
       "gpt     0.435584    0.686431            0.251            0.576\n",
       "claude  0.375950    0.516647            0.141            0.375\n",
       "qwen    0.407300    0.644342            0.237            0.582"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Aggregation per model\n",
    "\n",
    "gpt_text = df_per_question['gpt_text_metrics'].mean()\n",
    "gpt_text_image = df_per_question['gpt_text_img_metrics'].mean()\n",
    "claude_text = df_per_question['claude_text_metrics'].mean()\n",
    "claude_text_image = df_per_question['claude_text_img_metrics'].mean()\n",
    "qwen_text = df_per_question['qwen_text_metrics'].mean()\n",
    "qwen_text_image = df_per_question['qwen_text_img_metrics'].mean()\n",
    "\n",
    "results = pd.DataFrame(data = [[gpt_text, gpt_text_image], [claude_text, claude_text_image], [qwen_text, qwen_text_image]], columns = [\"text\", \"text_image\"], index=[\"gpt\", \"claude\", \"qwen\"])\n",
    "\n",
    "# Add uplifts\n",
    "results['absolute_uplift'] = results.apply(lambda row: round(row[\"text_image\"] - row[\"text\"], 3), axis =1)\n",
    "results['relative_uplift'] = results.apply(lambda row: round(row['absolute_uplift'] / row[\"text\"], 3), axis =1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>confidence_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt</th>\n",
       "      <td>-6.953747</td>\n",
       "      <td>3.859439e-10</td>\n",
       "      <td>0.251</td>\n",
       "      <td>(0.19, 0.312)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude</th>\n",
       "      <td>-4.765955</td>\n",
       "      <td>6.456427e-06</td>\n",
       "      <td>0.141</td>\n",
       "      <td>(0.095, 0.187)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen</th>\n",
       "      <td>-7.514773</td>\n",
       "      <td>2.587483e-11</td>\n",
       "      <td>0.237</td>\n",
       "      <td>(0.177, 0.297)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_statistic       p_value  mean_diff confidence_interval\n",
       "gpt       -6.953747  3.859439e-10      0.251       (0.19, 0.312)\n",
       "claude    -4.765955  6.456427e-06      0.141      (0.095, 0.187)\n",
       "qwen      -7.514773  2.587483e-11      0.237      (0.177, 0.297)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) Get inferential stats\n",
    "\n",
    "models = [\"gpt\", \"claude\", \"qwen\"]\n",
    "paired_ttest_results = {}\n",
    "\n",
    "std_devs = {\n",
    "    \"gpt\": {\"text\": 0.237257, \"text_img\": 0.194232},\n",
    "    \"claude\": {\"text\": 0.196352, \"text_img\": 0.123554},\n",
    "    \"qwen\": {\"text\": 0.220617, \"text_img\": 0.204615}\n",
    "}\n",
    "\n",
    "sample_size = 100 \n",
    "\n",
    "# Compute t-test and confidence intervals for each model\n",
    "for model in models:\n",
    "    text_mean = results.loc[model][\"text\"]\n",
    "    text_img_mean = results.loc[model][\"text_image\"]\n",
    "\n",
    "    # Compute the mean difference\n",
    "    mean_diff = text_img_mean - text_mean\n",
    "\n",
    "    # Compute standard deviation of the differences (assuming independence for approximation)\n",
    "    std_diff = np.sqrt(std_devs[model][\"text\"]**2 + std_devs[model][\"text_img\"]**2)\n",
    "\n",
    "    # Perform paired t-test\n",
    "    t_stat, p_value = ttest_rel(\n",
    "        np.random.normal(text_mean, std_devs[model][\"text\"], sample_size),\n",
    "        np.random.normal(text_img_mean, std_devs[model][\"text_img\"], sample_size)\n",
    "    )\n",
    "\n",
    "    # Compute confidence interval (95% CI)\n",
    "    t_critical = t.ppf(0.975, df=sample_size-1)  # 95% confidence, df = n-1\n",
    "    margin_of_error = t_critical * (std_diff / np.sqrt(sample_size))\n",
    "    confidence_interval = (round(mean_diff - margin_of_error, 3),round(mean_diff + margin_of_error, 3))\n",
    "\n",
    "    # Store results\n",
    "    paired_ttest_results[model] = {\n",
    "        \"t_statistic\": t_stat,\n",
    "        \"p_value\": p_value,\n",
    "        \"mean_diff\": round(mean_diff, 3),\n",
    "        \"confidence_interval\": confidence_interval\n",
    "    }\n",
    "\n",
    "stats_df = pd.DataFrame.from_dict(paired_ttest_results, orient='index')\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_image</th>\n",
       "      <th>absolute_uplift</th>\n",
       "      <th>relative_uplift</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>confidence_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt</th>\n",
       "      <td>0.435584</td>\n",
       "      <td>0.686431</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.576</td>\n",
       "      <td>-6.953747</td>\n",
       "      <td>3.859439e-10</td>\n",
       "      <td>0.251</td>\n",
       "      <td>(0.19, 0.312)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude</th>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.516647</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-4.765955</td>\n",
       "      <td>6.456427e-06</td>\n",
       "      <td>0.141</td>\n",
       "      <td>(0.095, 0.187)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen</th>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.644342</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-7.514773</td>\n",
       "      <td>2.587483e-11</td>\n",
       "      <td>0.237</td>\n",
       "      <td>(0.177, 0.297)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text_image  absolute_uplift  relative_uplift  t_statistic  \\\n",
       "gpt     0.435584    0.686431            0.251            0.576    -6.953747   \n",
       "claude  0.375950    0.516647            0.141            0.375    -4.765955   \n",
       "qwen    0.407300    0.644342            0.237            0.582    -7.514773   \n",
       "\n",
       "             p_value  mean_diff confidence_interval  \n",
       "gpt     3.859439e-10      0.251       (0.19, 0.312)  \n",
       "claude  6.456427e-06      0.141      (0.095, 0.187)  \n",
       "qwen    2.587483e-11      0.237      (0.177, 0.297)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_final = results.join(stats_df)\n",
    "results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_value << 0.05 => all results are stat significant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
